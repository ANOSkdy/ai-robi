export const runtime = 'nodejs';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { rateLimit } from '@/lib/utils/rate-limit';
import { withBackoff } from '@/lib/utils/backoff';
import { CVSchema } from '@/lib/ai/schema';
import { buildCvUserPrompt, systemText } from '@/lib/ai/prompt';

export async function POST(req: Request) {
  if (!await rateLimit(req)) {
    return Response.json({ error: 'Too Many Requests' }, { status: 429 });
  }
  const { jobProfile, experiences } = await req.json();

  // P1邵ｺ・ｧ邵ｺ・ｯ user 郢ｧ・ｳ郢晢ｽｳ郢昴・縺冗ｹｧ・ｹ郢晏沺邏幄厄ｽ｢邵ｺ・ｯ驍・ｽ｡騾｡・･陋ｹ繝ｻ  const profileText = JSON.stringify(jobProfile, null, 2);
  const experiencesText = JSON.stringify(experiences, null, 2);
  const prompt = buildCvUserPrompt(profileText, experiencesText);

  const key = process.env.GEMINI_API_KEY;
  if (!key) {
    // 鬪ｰ・ｵ隴幢ｽｪ髫ｪ・ｭ陞ｳ螢ｽ蜃ｾ邵ｺ・ｯ 502 邵ｺ・ｧ鬨ｾ螟り｡阪・驛・ｽｨ・ｭ髫ｪ蝓溷ｩｿ鬩･譎｢・ｼ繝ｻ    return Response.json({ error: 'AI郢ｧ・ｭ郢晢ｽｼ隴幢ｽｪ髫ｪ・ｭ陞ｳ螢ｹ繝ｻ邵ｺ貅假ｽ・墓ｻ薙・闕ｳ讎雁ｺ・ }, { status: 502 });
  }

  const genAI = new GoogleGenerativeAI(key);
  const model = genAI.getGenerativeModel({ model: 'gemini-1.5-pro', systemInstruction: systemText });

  const text = await withBackoff(async () => {
  const res = await model.generateContent({
    contents: [{ role: "user", parts: [{ text: prompt }] }],
    generationConfig: { maxOutputTokens: 1024, temperature: 0.4 }
  });
  return res.response.text();
});
const stripCodeFence = (s:string) => s.replace(/```json\s*|```/g, "").trim();
const textClean = stripCodeFence(text);try {
    const json = CVSchema.parse(JSON.parse(textClean));
    return Response.json(json);
  } catch {
    return Response.json({ error: 'AI陷・ｽｺ陷牙ｸ吶・陟厄ｽ｢陟台ｸ岩ｲ闕ｳ閧ｴ・ｭ・｣邵ｺ・ｧ邵ｺ繝ｻ }, { status: 502 });
  }
}
